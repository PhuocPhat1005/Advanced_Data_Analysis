# frontend/app.py

import os
import json
import base64
import requests
import time
import streamlit as st
from datetime import datetime

# --- C·∫•u h√¨nh ---
BACKEND = os.getenv("BACKEND_URL", "http://localhost:8000")
HISTORY_FILE = "history/chat_history.json"

st.set_page_config(page_title="üìä Tiki Data Analyzer", layout="wide")

# --- Step 0: L·∫•y danh s√°ch v√† summary c·ªßa c√°c file g·ªëc t·ª´ backend ---
@st.cache_data(show_spinner=False)
def load_default_summaries():
    try:
        res = requests.get(f"{BACKEND}/ai_agent/llm_agent/defaults")
        res.raise_for_status()
        data = res.json()  # list of {name, summary}
        return {item["name"]: item["summary"] for item in data}
    except Exception:
        return {}

default_summaries = load_default_summaries()
default_dfs = list(default_summaries.keys())

# --- Sidebar: ch·ªçn data g·ªëc ƒë·ªÉ include ---
st.sidebar.title("Ch·ªçn DataFrame")
include_defaults = st.sidebar.multiselect(
    "Ch·ªçn data m·∫∑c ƒë·ªãnh ƒë·ªÉ include:",
    default_dfs,
    default=default_dfs
)

# N·∫øu ch∆∞a c√≥ trong session, kh·ªüi dict l∆∞u c√°c summary (g·ªëc + upload)
if "dfs" not in st.session_state:
    st.session_state.dfs = {name: default_summaries[name] for name in include_defaults}

# --- Sidebar: upload th√™m CSV ---
st.sidebar.markdown("---")
uploaded = st.sidebar.file_uploader(
    "Upload CSV (nhi·ªÅu file)", type="csv", accept_multiple_files=True
)
if uploaded:
    for f in uploaded:
        raw = f.read().decode("utf-8")
        b64 = base64.b64encode(raw.encode()).decode()
        res = requests.post(
            f"{BACKEND}/ai_agent/llm_agent/upload",
            json={"df_name": f.name, "csv_content": b64}
        )
        if res.ok:
            info = res.json()
            st.sidebar.success(f"ƒê√£ t·∫£i: {info['name']}")
            st.session_state.dfs[info["name"]] = info["summary"]
        else:
            st.sidebar.error(f"Upload l·ªói: {res.text}")

# --- Sidebar: c·∫•u h√¨nh model & prompt ---
st.sidebar.markdown("---")
st.sidebar.title("C√†i ƒë·∫∑t LLM & Prompt")

model_options = [
    "gemini-2.5-pro", "gemini-2.5-flash",
    "gemini-2.5-flash-lite", "gemini-2.0-flash",
    "gemini-2.0-flash-lite"
]
selected_model = st.sidebar.selectbox("Ch·ªçn model Gemini", model_options)

prompt_type = st.sidebar.radio("Lo·∫°i prompt", ["custom", "preset"])
custom_prompt = st.sidebar.text_area("Nh·∫≠p prompt tu·ª≥ ch·ªânh") if prompt_type=="custom" else ""
preset_key = st.sidebar.selectbox("Ch·ªçn prompt m·∫´u", ["overview","compare"]) if prompt_type=="preset" else ""

# --- Hi·ªÉn th·ªã summary c·ªßa t·∫•t c·∫£ DataFrame ƒëang include ---
st.markdown("## üìã T·ªïng h·ª£p DataFrame")
for name, summary in st.session_state.dfs.items():
    with st.expander(name, expanded=False):
        st.text(summary)

# --- Chat area ---
if "chat" not in st.session_state:
    st.session_state.chat = []

st.markdown("---")
query = st.text_input("Nh·∫≠p c√¢u h·ªèi v√† Enter ƒë·ªÉ g·ª≠i:", "")

if query:
    st.session_state.chat.append({"role": "user", "text": query})

    # G·ªçi API v·ªõi spinner
    with st.spinner("Agent ƒëang x·ª≠ l√Ω‚Ä¶"):
        payload = {
            "model": selected_model,
            "prompt_type": prompt_type,
            "custom_prompt": custom_prompt,
            "preset_key": preset_key,
            "user_query": query,
            "df_names": list(st.session_state.dfs.keys())
        }
        res = requests.post(f"{BACKEND}/ai_agent/llm_agent/ask", json=payload)

    if res.ok:
        full_resp = res.json().get("answer", "")
    else:
        full_resp = f"Error: {res.text}"

    # Typing effect
    placeholder = st.empty()
    buf = ""
    for ch in full_resp:
        buf += ch
        placeholder.markdown(f"**Agent:** {buf}")
        time.sleep(0.01)
    st.session_state.chat.append({"role": "assistant", "text": full_resp})

# Render l·ªãch s·ª≠ chat
st.markdown("## üí¨ L·ªãch s·ª≠ chat")
for msg in st.session_state.chat:
    prefix = "**B·∫°n:**" if msg["role"]=="user" else "**Agent:**"
    st.markdown(f"{prefix} {msg['text']}")

# --- L∆∞u l·ªãch s·ª≠ ---
if st.button("L∆∞u l·ªãch s·ª≠"):
    os.makedirs("history", exist_ok=True)
    record = {
        "timestamp": datetime.now().isoformat(),
        "model": selected_model,
        "prompt_type": prompt_type,
        "preset_key": preset_key,
        "included_dfs": list(st.session_state.dfs.keys()),
        "chat": st.session_state.chat
    }
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(record, f, ensure_ascii=False, indent=2)
    st.success(f"ƒê√£ l∆∞u l·ªãch s·ª≠ v√†o `{HISTORY_FILE}`")
