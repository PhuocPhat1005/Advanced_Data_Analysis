import os
import json
import base64
import requests
import time
import streamlit as st
from datetime import datetime

# URL backend (c√≥ th·ªÉ override qua ENV)
BACKEND = os.getenv("BACKEND_URL", "http://localhost:8000")
HISTORY_FILE = "history/chat_history.json"

st.set_page_config(page_title="üìä Tiki Data Analyzer", layout="wide")

# --- Sidebar: c·∫•u h√¨nh chung ---
st.sidebar.title("C√†i ƒë·∫∑t chung")

# Ch·ªçn model Gemini
model_options = [
    "gemini-2.5-pro", "gemini-2.5-flash",
    "gemini-2.5-flash-lite", "gemini-2.0-flash",
    "gemini-2.0-flash-lite"
]
selected_model = st.sidebar.selectbox("Ch·ªçn model Google Gemini", model_options)

# Ch·ªçn lo·∫°i prompt
prompt_type = st.sidebar.radio("Ch·ªçn lo·∫°i prompt", ["custom", "preset", "suggest"])
custom_prompt = ""
preset_key = ""

if prompt_type == "custom":
    custom_prompt = st.sidebar.text_area("Nh·∫≠p prompt tu·ª≥ ch·ªânh")
elif prompt_type == "preset":
    preset_key = st.sidebar.selectbox("Ch·ªçn prompt m·∫´u", ["overview", "compare"])

st.sidebar.markdown("---")

# --- Upload CSV ---
uploaded = st.sidebar.file_uploader(
    "Upload CSV (h·ªó tr·ª£ nhi·ªÅu file)", type="csv", accept_multiple_files=True
)

if uploaded:
    if "dfs" not in st.session_state:
        st.session_state.dfs = {}
    for f in uploaded:
        raw = f.read().decode("utf-8")
        b64 = base64.b64encode(raw.encode()).decode()
        # G·ªçi API upload
        res = requests.post(
            f"{BACKEND}/ai_agent/llm_agent/upload",
            json={"df_name": f.name, "csv_content": b64}
        )
        if res.ok:
            info = res.json()
            st.sidebar.success(f"ƒê√£ t·∫£i: {info['name']}")
            # L∆∞u summary ƒë·ªÉ render
            st.session_state.dfs[info["name"]] = info["summary"]
        else:
            st.sidebar.error(f"Upload l·ªói: {res.text}")

# Hi·ªÉn th·ªã t√≥m t·∫Øt cho t·ª´ng DataFrame
if st.session_state.get("dfs"):
    for name, summary in st.session_state.dfs.items():
        with st.expander(f"Summary: {name}"):
            st.text(summary)

st.sidebar.markdown("---")

# --- Chat area ---
if "chat" not in st.session_state:
    st.session_state.chat = []

# Input user
query = st.text_input("Nh·∫≠p c√¢u h·ªèi v√† Enter ƒë·ªÉ g·ª≠i:", "")

if query:
    # 1. Append user message
    st.session_state.chat.append({"role": "user", "text": query})

    # 2. G·ªçi API trong spinner
    with st.spinner("Agent ƒëang suy nghƒ©, xin ch·ªù..."):
        payload = {
            "model": selected_model,
            "prompt_type": prompt_type,
            "custom_prompt": custom_prompt,
            "preset_key": preset_key,
            "df_names": list(st.session_state.dfs.keys())
        }
        res = requests.post(f"{BACKEND}/ai_agent/llm_agent/ask", json=payload)

    # 3. X·ª≠ l√Ω response
    if res.ok:
        full_resp = res.json().get("answer", "")
    else:
        full_resp = f"Error: {res.text}"

    # 4. Typing effect: placeholder ƒë·ªÉ update d·∫ßn
    placeholder = st.empty()
    text_buf = ""
    for ch in full_resp:
        text_buf += ch
        placeholder.markdown(f"**Agent:** {text_buf}")
        time.sleep(0.01)  # ƒëi·ªÅu ch·ªânh t·ªëc ƒë·ªô g√µ
    # Sau khi in h·∫øt, th√™m v√†o l·ªãch s·ª≠
    st.session_state.chat.append({"role": "assistant", "text": full_resp})

# Render to√†n b·ªô l·ªãch s·ª≠ chat
for msg in st.session_state.chat:
    if msg["role"] == "user":
        st.markdown(f"**B·∫°n:** {msg['text']}")
    else:
        st.markdown(f"**Agent:** {msg['text']}")

# --- L∆∞u l·ªãch s·ª≠ ---
if st.button("L∆∞u l·ªãch s·ª≠"):
    os.makedirs("history", exist_ok=True)
    record = {
        "timestamp": datetime.now().isoformat(),
        "model": selected_model,
        "prompt_type": prompt_type,
        "preset_key": preset_key,
        "chat": st.session_state.chat
    }
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(record, f, ensure_ascii=False, indent=2)
    st.success(f"ƒê√£ l∆∞u l·ªãch s·ª≠ v√†o `{HISTORY_FILE}`")
